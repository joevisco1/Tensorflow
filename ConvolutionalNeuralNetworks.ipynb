{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow-addons"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jNtQdenxUnY1",
        "outputId": "64fb7e7d-d551-4365-fddc-1fdc8416ac15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (591 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/591.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m583.7/591.0 kB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m591.0/591.0 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow-addons) (23.1)\n",
            "Collecting typeguard<3.0.0,>=2.7 (from tensorflow-addons)\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Installing collected packages: typeguard, tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.20.0 typeguard-2.13.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w-4gv25aYbRk"
      },
      "outputs": [],
      "source": [
        "import urllib\n",
        "import zipfile\n",
        "import random\n",
        "import tensorflow as tf\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This function downloads and extracts the dataset to the directory that\n",
        "# contains this file.\n",
        "# DO NOT CHANGE THIS CODE\n",
        "# (unless you need to change https to http)\n",
        "\n",
        "\n",
        "def download_and_extract_data():\n",
        "    url = 'https://storage.googleapis.com/download.tensorflow.org/data/certificate/satellitehurricaneimages.zip'\n",
        "    urllib.request.urlretrieve(url, 'satellitehurricaneimages.zip')\n",
        "    with zipfile.ZipFile('satellitehurricaneimages.zip', 'r') as zip_ref:\n",
        "        zip_ref.extractall()\n"
      ],
      "metadata": {
        "id": "drL7O2tiYkan"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "\n",
        "\n",
        "callbacks = [\n",
        "        # EarlyStopping(\n",
        "        #     monitor='val_accuracy',\n",
        "        #     min_delta=1e-4,\n",
        "        #     patience=3,\n",
        "        #     verbose=1\n",
        "        # )\n",
        "      #  ,\n",
        "        ModelCheckpoint(\n",
        "            filepath='mymodel.h5',\n",
        "            monitor='val_accuracy',\n",
        "            mode='max',\n",
        "            save_best_only=True,\n",
        "            save_weights_only=False,\n",
        "            verbose=1\n",
        "        )\n",
        "        # ,\n",
        "\n",
        "        # ReduceLROnPlateau(monitor=\"val_loss\",\n",
        "        #                                         factor=0.2,  # multiply the learning rate by 0.2 (reduce by 5x)\n",
        "        #                                         patience=2,\n",
        "        #                                         verbose=1,  # print out when learning rate goes down\n",
        "        #                                         min_lr=1e-7)\n",
        "        ]\n",
        "\n"
      ],
      "metadata": {
        "id": "jjDN8xeYbeY1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "download_and_extract_data()\n",
        "IMG_SIZE = (128, 128)\n",
        "BATCH_SIZE = 64\n",
        "# The following code reads the training and validation data from their\n",
        "# respective directories, resizes them into the specified image size\n",
        "# and splits them into batches. You must fill in the image_size\n",
        "# argument for both training and validation data.\n",
        "# HINT: Image size is a tuple\n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  directory='train/',\n",
        "  image_size=IMG_SIZE,\n",
        "  label_mode='binary',\n",
        "  shuffle=True,\n",
        "  batch_size=BATCH_SIZE)\n",
        "\n",
        "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  directory='validation/',\n",
        "  image_size= IMG_SIZE,\n",
        "  label_mode='binary',\n",
        "  batch_size=BATCH_SIZE,\n",
        "  shuffle=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TaJCG5T8qy8M",
        "outputId": "314a0ef4-3435-4ad7-c78f-7924337f8244"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 10000 files belonging to 2 classes.\n",
            "Found 2000 files belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "ka4hXTmV5DNh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(image, label):\n",
        "    image = image/255\n",
        "    label = label/255\n",
        "\n",
        "    image = tf.keras.applications.inception_v3.preprocess_input(image)\n",
        "\n",
        "\n",
        "    return image, label\n",
        "\n"
      ],
      "metadata": {
        "id": "RiP707WIYllz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = train_ds.map(\n",
        "preprocess, num_parallel_calls=tf.data.experimental.AUTOTUNE).prefetch(\n",
        "tf.data.experimental.AUTOTUNE)\n",
        "val_ds = val_ds.map(\n",
        "preprocess, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "train_ds, val_ds\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NgIaXs1Kq-wT",
        "outputId": "e11fbf6e-9c05-474f-e625-f6c1bb9db5c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<_PrefetchDataset element_spec=(TensorSpec(shape=(None, 128, 128, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 1), dtype=tf.float32, name=None))>,\n",
              " <_ParallelMapDataset element_spec=(TensorSpec(shape=(None, 128, 128, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 1), dtype=tf.float32, name=None))>)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Create a data augmentation stage with horizontal flipping, rotations, zooms\n",
        "data_augmentation = keras.Sequential(\n",
        "    [\n",
        "        layers.RandomFlip(\"horizontal\"),\n",
        "        layers.RandomRotation(0.1),\n",
        "        layers.RandomZoom(0.1),\n",
        "    ]\n",
        ")\n",
        "\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "  layers.preprocessing.RandomFlip(\"horizontal_and_vertical\"),\n",
        "  layers.preprocessing.RandomRotation(0.2),\n",
        "  layers.preprocessing.RandomZoom(height_factor=(0.2, 0.3), width_factor=(0.2, 0.3)),\n",
        "  layers.preprocessing.RandomTranslation(0.3, 0.3, fill_mode='reflect', interpolation='bilinear',)\n",
        "])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "xVca6lbJO6CX",
        "outputId": "c8293d15-8f68-48f0-b023-2437b6da9cd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-60-7e66f4c5cb85>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m data_augmentation = tf.keras.Sequential([\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRandomFlip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"horizontal_and_vertical\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRandomRotation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRandomZoom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheight_factor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth_factor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRandomTranslation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'reflect'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'bilinear'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow.keras.layers' has no attribute 'preprocessing'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1. / 255,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest')\n",
        "\n",
        "validation_datagen = ImageDataGenerator(rescale=1 / 255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    'train/',  # This is the source directory for training images\n",
        "    target_size=(300, 300),  # All images will be resized to 150x150\n",
        "    batch_size=1,\n",
        "    # Since we use binary_crossentropy loss, we need binary labels\n",
        "    class_mode='binary')\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "    'validation/',  # This is the source directory for training images\n",
        "    target_size=(300, 300),  # All images will be resized to 150x150\n",
        "    batch_size=1,\n",
        "    # Since we use binary_crossentropy loss, we need binary labels\n",
        "    class_mode='binary')"
      ],
      "metadata": {
        "id": "E91G0KpAWqpc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "callbacks = [\n",
        "ModelCheckpoint(\n",
        "            filepath='mymodel.h5',\n",
        "            monitor='val_accuracy',\n",
        "            mode='max',\n",
        "            save_best_only=True,\n",
        "            save_weights_only=False,\n",
        "            verbose=1\n",
        "        ),\n",
        "      ReduceLROnPlateau(monitor='val_loss', factor=0.8,\n",
        "                                                 patience=3, min_lr=1e-5, verbose=1)\n",
        "    ]"
      ],
      "metadata": {
        "id": "AMOBO-lHGf2j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds, val_ds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qpllLQxzHV4j",
        "outputId": "9f7e5c17-dc92-4af0-c8cf-b43fa39bd62e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<_PrefetchDataset element_spec=(TensorSpec(shape=(None, 128, 128, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 1), dtype=tf.float32, name=None))>,\n",
              " <_ParallelMapDataset element_spec=(TensorSpec(shape=(None, 128, 128, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 1), dtype=tf.float32, name=None))>)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.request\n",
        "import os\n",
        "import zipfile\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "\n",
        "#base_model = efn.EfficientNetB0(input_shape = (224, 224, 3), include_top = False, weights = 'imagenet')\n",
        "\n",
        "\n",
        "\n",
        "weights_url = \"https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\"\n",
        "weights_file = \"inception_v3.h5\"\n",
        "urllib.request.urlretrieve(weights_url, weights_file)\n",
        "\n",
        "pre_trained_model = InceptionV3(input_shape=(128, 128, 3),\n",
        "                                include_top=False,\n",
        "                                weights=None)\n",
        "\n",
        "pre_trained_model.load_weights(weights_file)\n",
        "\n",
        "for layer in pre_trained_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# pre_trained_model.summary()\n",
        "\n",
        "last_layer = pre_trained_model.get_layer('mixed7')\n",
        "# print('last layer output shape: ', last_layer.output_shape)\n",
        "last_output = last_layer.output\n",
        "\n",
        "# Flatten the output layer to 1 dimension\n",
        "x = layers.Flatten()(last_output)\n",
        "# Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
        "x = layers.Dense(1024, activation='relu')(x)\n",
        "# Add a dropout rate of 0.2\n",
        "x = layers.Dropout(0.2)(x)\n",
        "# Add a final sigmoid layer for classification\n",
        "x = layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "model = Model(pre_trained_model.input, x)\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1. / 255,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest')\n",
        "\n",
        "validation_datagen = ImageDataGenerator(rescale=1 / 255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    'train/',  # This is the source directory for training images\n",
        "    target_size=(128, 128),  # All images will be resized to 150x150\n",
        "    batch_size=64,\n",
        "    # Since we use binary_crossentropy loss, we need binary labels\n",
        "    class_mode='binary')\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "    'validation/',  # This is the source directory for training images\n",
        "    target_size=(128, 128),  # All images will be resized to 150x150\n",
        "    batch_size=64,\n",
        "    # Since we use binary_crossentropy loss, we need binary labels\n",
        "    class_mode='binary')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "model.fit(\n",
        "        train_ds,\n",
        "        steps_per_epoch=8,\n",
        "        epochs=100,\n",
        "        verbose=1,\n",
        "        validation_data=val_ds,\n",
        "        validation_steps=8,\n",
        "        callbacks=callbacks\n",
        "    )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aY0paii74w4J",
        "outputId": "7cbd9720-81c9-42cb-fe6c-9ce9437bf0e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "last layer output shape:  (None, 6, 6, 768)\n",
            "Found 10000 images belonging to 2 classes.\n",
            "Found 2000 images belonging to 2 classes.\n",
            "Epoch 1/100\n",
            "8/8 [==============================] - ETA: 0s - loss: 330.1458 - accuracy: 0.5137\n",
            "Epoch 1: val_accuracy improved from -inf to 1.00000, saving model to mymodel.h5\n",
            "8/8 [==============================] - 6s 387ms/step - loss: 330.1458 - accuracy: 0.5137 - val_loss: 1.0221e-17 - val_accuracy: 1.0000\n",
            "Epoch 2/100\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 48.0024 - accuracy: 0.5714\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "8/8 [==============================] - 1s 88ms/step - loss: 45.0615 - accuracy: 0.5996 - val_loss: 1.5335 - val_accuracy: 0.9512\n",
            "Epoch 3/100\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 30.8525 - accuracy: 0.7143\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "8/8 [==============================] - 1s 88ms/step - loss: 28.2347 - accuracy: 0.7246 - val_loss: 26.8000 - val_accuracy: 0.5410\n",
            "Epoch 4/100\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 17.4377 - accuracy: 0.7388\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "8/8 [==============================] - 1s 88ms/step - loss: 17.0886 - accuracy: 0.7441 - val_loss: 1.1980 - val_accuracy: 0.9414\n",
            "Epoch 5/100\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 12.1061 - accuracy: 0.7522\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "8/8 [==============================] - 1s 88ms/step - loss: 12.0407 - accuracy: 0.7461 - val_loss: 12.1417 - val_accuracy: 0.5527\n",
            "Epoch 6/100\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 7.9957 - accuracy: 0.7344\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "8/8 [==============================] - 1s 88ms/step - loss: 8.1395 - accuracy: 0.7266 - val_loss: 5.0802 - val_accuracy: 0.6836\n",
            "Epoch 7/100\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 4.0322 - accuracy: 0.7679\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "8/8 [==============================] - 1s 90ms/step - loss: 4.2086 - accuracy: 0.7637 - val_loss: 1.4386 - val_accuracy: 0.8281\n",
            "Epoch 8/100\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 2.4474 - accuracy: 0.7411\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "8/8 [==============================] - 1s 90ms/step - loss: 2.3084 - accuracy: 0.7559 - val_loss: 2.0606 - val_accuracy: 0.7617\n",
            "Epoch 9/100\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 1.6103 - accuracy: 0.8371\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "8/8 [==============================] - 1s 89ms/step - loss: 1.5889 - accuracy: 0.8320 - val_loss: 0.7473 - val_accuracy: 0.8105\n",
            "Epoch 10/100\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.8790 - accuracy: 0.7567\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "8/8 [==============================] - 1s 87ms/step - loss: 0.8194 - accuracy: 0.7656 - val_loss: 0.4295 - val_accuracy: 0.8613\n",
            "Epoch 11/100\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.7378 - accuracy: 0.7545\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "8/8 [==============================] - 1s 89ms/step - loss: 0.7342 - accuracy: 0.7559 - val_loss: 0.1653 - val_accuracy: 0.9121\n",
            "Epoch 12/100\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.5098 - accuracy: 0.8080\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "8/8 [==============================] - 1s 89ms/step - loss: 0.5022 - accuracy: 0.8086 - val_loss: 0.5857 - val_accuracy: 0.6250\n",
            "Epoch 13/100\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.5642 - accuracy: 0.7500\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "8/8 [==============================] - 1s 89ms/step - loss: 0.5532 - accuracy: 0.7500 - val_loss: 0.3693 - val_accuracy: 0.8770\n",
            "Epoch 14/100\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.4684 - accuracy: 0.7879\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "8/8 [==============================] - 1s 88ms/step - loss: 0.5017 - accuracy: 0.7793 - val_loss: 0.3404 - val_accuracy: 0.8828\n",
            "Epoch 15/100\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.5141 - accuracy: 0.7835\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "8/8 [==============================] - 1s 89ms/step - loss: 0.4931 - accuracy: 0.7930 - val_loss: 0.4339 - val_accuracy: 0.8555\n",
            "Epoch 16/100\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.3906 - accuracy: 0.8549\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "8/8 [==============================] - 1s 89ms/step - loss: 0.3770 - accuracy: 0.8555 - val_loss: 0.3522 - val_accuracy: 0.8867\n",
            "Epoch 17/100\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.5806 - accuracy: 0.8147\n",
            "Epoch 17: val_accuracy did not improve from 1.00000\n",
            "8/8 [==============================] - 1s 89ms/step - loss: 0.5747 - accuracy: 0.8184 - val_loss: 0.5242 - val_accuracy: 0.8047\n",
            "Epoch 18/100\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.4469 - accuracy: 0.8080\n",
            "Epoch 18: val_accuracy did not improve from 1.00000\n",
            "8/8 [==============================] - 1s 89ms/step - loss: 0.4620 - accuracy: 0.8008 - val_loss: 0.2434 - val_accuracy: 0.9199\n",
            "Epoch 19/100\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.8094 - accuracy: 0.7411\n",
            "Epoch 19: val_accuracy did not improve from 1.00000\n",
            "8/8 [==============================] - 1s 88ms/step - loss: 0.7577 - accuracy: 0.7520 - val_loss: 0.1368 - val_accuracy: 0.9473\n",
            "Epoch 20/100\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.4275 - accuracy: 0.7941"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 800 batches). You may need to use the repeat() function when building your dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 20: val_accuracy did not improve from 1.00000\n",
            "8/8 [==============================] - 1s 71ms/step - loss: 0.4275 - accuracy: 0.7941 - val_loss: 0.6959 - val_accuracy: 0.6172\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb21319cfd0>"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.request\n",
        "import os\n",
        "import zipfile\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.applications import EfficientNetB7\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# base_model = EfficientNetB7(input_shape = (128, 128, 3), include_top = False, weights = 'imagenet', drop_connect_rate=0.4)\n",
        "\n",
        "# for layer in base_model.layers:\n",
        "#     layer.trainable = False\n",
        "\n",
        "\n",
        "\n",
        "# model = tf.keras.Sequential([\n",
        "#                                 base_model,\n",
        "#                                 tf.keras.layers.GlobalAveragePooling2D(name=\"Layer1\"),\n",
        "#                                 tf.keras.layers.Dropout(0.4),\n",
        "#                                 tf.keras.layers.Dense(1, activation='softmax')\n",
        "#     ])\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(),loss='binary_crossentropy',metrics=['accuracy'], run_eagerly=True)\n",
        "\n",
        "\n",
        "\n",
        "# train_datagen = ImageDataGenerator(\n",
        "#     rescale=1. / 255,\n",
        "#     rotation_range=40,\n",
        "#     width_shift_range=0.2,\n",
        "#     height_shift_range=0.2,\n",
        "#     shear_range=0.2,\n",
        "#     zoom_range=0.2,\n",
        "#     horizontal_flip=True,\n",
        "#     fill_mode='nearest')\n",
        "\n",
        "# validation_datagen = ImageDataGenerator(rescale=1 / 255)\n",
        "\n",
        "# train_generator = train_datagen.flow_from_directory(\n",
        "#     'train/',  # This is the source directory for training images\n",
        "#     target_size=(128, 128),  # All images will be resized to 150x150\n",
        "#     batch_size=64,\n",
        "#     # Since we use binary_crossentropy loss, we need binary labels\n",
        "#     class_mode='binary')\n",
        "\n",
        "# validation_generator = validation_datagen.flow_from_directory(\n",
        "#     'validation/',  # This is the source directory for training images\n",
        "#     target_size=(128, 128),  # All images will be resized to 150x150\n",
        "#     batch_size=64,\n",
        "#     # Since we use binary_crossentropy loss, we need binary labels\n",
        "#     class_mode='binary')\n",
        "\n",
        "\n",
        "#train_ds, val_ds\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "iz7Cgn6ycdFO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(\n",
        "        train_ds,\n",
        "        steps_per_epoch=100,\n",
        "        epochs=10,\n",
        "        verbose=1,\n",
        "        validation_data=val_ds,\n",
        "        validation_steps=8,\n",
        "        callbacks=callbacks\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "7xHWr9XTV-92",
        "outputId": "4c2999a4-1933-4861-9073-d4008c44d7c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-ab4a580d8aa8>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m model.fit(\n\u001b[0m\u001b[1;32m      2\u001b[0m         \u001b[0mtrain_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/version_utils.py\u001b[0m in \u001b[0;36mdisallow_legacy_graph\u001b[0;34m(cls_name, method_name)\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;34m\"eager mode enabled.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         )\n\u001b[0;32m--> 126\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Calling `Model.fit` in graph mode is not supported when the `Model` instance was constructed with eager mode enabled. Please construct your `Model` instance in graph mode or call `Model.fit` with eager mode enabled."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Input, BatchNormalization, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "\n",
        "def create_model():\n",
        "  base_model = ResNet50(include_top=False, weights='imagenet', input_shape=(128, 128, 3))\n",
        "  # for layer in base_model.layers[:-30]:\n",
        "  #   layer.trainable = False\n",
        "  augmented = data_augmentation(base_model)\n",
        "  resnet = base_model(augmented)\n",
        "  pooling = layers.GlobalAveragePooling2D()(resnet)\n",
        "  dropout = layers.Dropout(0.4)(pooling)\n",
        "  outputs = Dense(len(class_types), activation=\"softmax\")(dropout)\n",
        "  model = Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "  return model\n",
        "\n",
        "model = create_model()\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=5e-4),\n",
        "              metrics=['acc'])\n",
        "\n",
        "\n",
        "\n",
        "history = model.fit(train_ds,\n",
        "                    epochs = 60,\n",
        "                    validation_data=val_ds,\n",
        "                    callbacks=callbacks)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 502
        },
        "id": "yZwKmDF4V6CR",
        "outputId": "9c3a6ca1-6994-4856-8a84-17c8fb1ae296"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs=<keras.engine.functional.Functional object at 0x7fb1ca547280>. Consider rewriting this model with the Functional API.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-59-b5f6169da00e>\u001b[0m in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-59-b5f6169da00e>\u001b[0m in \u001b[0;36mcreate_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0;31m# for layer in base_model.layers[:-30]:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0;31m#   layer.trainable = False\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m   \u001b[0maugmented\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_augmentation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m   \u001b[0mresnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maugmented\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0mpooling\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGlobalAveragePooling2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresnet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    101\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling layer 'random_flip_5' (type RandomFlip).\n\nAttempt to convert a value (<keras.engine.functional.Functional object at 0x7fb1ca547280>) with an unsupported type (<class 'keras.engine.functional.Functional'>) to a Tensor.\n\nCall arguments received by layer 'random_flip_5' (type RandomFlip):\n  • inputs=<keras.engine.functional.Functional object at 0x7fb1ca547280>\n  • training=True"
          ]
        }
      ]
    }
  ]
}